# LLM Paper Assistant Documentation

## Project Overview
The `llm_paper_assistant` is a Streamlit-based application designed to assist researchers in searching, uploading, and comparing academic papers from local storage, arXiv, and Semantic Scholar. It leverages natural language processing (NLP), semantic search, and vector embeddings to provide a user-friendly interface for paper management and analysis. Key features include PDF generation for comparison reports, semantic similarity analysis, and memory management for search history.

### Objectives
- Enable users to search for papers using natural language commands.
- Support uploading and indexing local PDF papers with unique file hashes.
- Compare paper abstracts semantically, generating structured reports in English.
- Export professional PDF reports with optimized formatting (title, date, page numbers, separators).
- Ensure robust error handling and memory management for seamless user experience.

## System Architecture
The project is modular, with the following core components:
- **ui.py**: Handles the Streamlit user interface, including search, upload, and PDF generation.
- **compare.py**: Performs semantic comparison of paper abstracts using `all-MiniLM-L6-v2` embeddings and `gpt-3.5-turbo` for structured output.
- **vector_store.py**: Manages semantic search using `all-MiniLM-L6-v2` embeddings and ChromaDB for vector storage.
- **memory_manager.py**: Stores search history and paper metadata with a 30-day retention period, supporting automatic re-search for empty results.
- **pdf_processor.py**: Extracts titles and abstracts from PDFs and generates file hashes (`hashlib.md5`).
- **database.py**: Interfaces with a PostgreSQL database to store paper metadata and file hashes.
- **web_search.py**: Queries arXiv and Semantic Scholar for online papers.
- **nlp.py**: Parses user intents from natural language commands.

### Dependencies
- Python 3.8+
- Libraries: `streamlit`, `reportlab`, `sentence-transformers`, `chromadb`, `openai`, `numpy`, `tenacity`, `fitz` (PyMuPDF)
- External Services: OpenAI API (`gpt-3.5-turbo`) for comparison generation

## Installation Guide
1. **Clone the Repository**:
   ```bash
   git clone https://github.com/your-username/llm_paper_assistant.git
   cd llm_paper_assistant
   ```

2. **Set Up a Virtual Environment**:
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install Dependencies**:
   ```bash
   pip install streamlit reportlab sentence-transformers chromadb openai numpy tenacity pymupdf
   ```

4. **Configure Environment Variables**:
   Create a `.env` file in the project root:
   ```env
   OPENAI_API_KEY=your-api-key
   ```

5. **Set Up PostgreSQL**:
   - Install PostgreSQL and create a database (e.g., `paper_assistant`).
   - Update `database.py` with your database credentials (host, port, user, password).
   - Initialize the database schema:
     ```sql
     CREATE TABLE papers (
         paper_id SERIAL PRIMARY KEY,
         title TEXT,
         abstract TEXT,
         file_hash VARCHAR(32) UNIQUE,
         source TEXT,
         created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
     );
     ```

6. **Run the Application**:
   ```bash
   streamlit run ui.py
   ```
   Access the app at `http://localhost:8501`.

## Feature Description
1. **Natural Language Command Interface**:
   - Users can input commands like `search arxiv for vision transformer` or `compare arxiv paper 1 with local paper 6`.
   - Supported intents: search (arXiv, Semantic Scholar, local), compare, view history.

2. **Paper Search**:
   - **arXiv Search**: Queries arXiv for papers by keyword, returns title, abstract, and link.
   - **Semantic Scholar Search**: Searches by keyword, max results, and date range, returning detailed metadata (authors, venue, DOI).
   - **Local Search**: Queries local PDFs using semantic embeddings (`all-MiniLM-L6-v2`).

3. **Paper Upload**:
   - Upload PDF files via the sidebar, extracting title and abstract.
   - Generates unique file hashes (`hashlib.md5`) to prevent duplicates.
   - Stores metadata in PostgreSQL and embeddings in ChromaDB.

4. **Paper Comparison**:
   - Compares two abstracts semantically using `all-MiniLM-L6-v2` for similarity and `gpt-3.5-turbo` for structured output.
   - Output format: English bullet points (Similarities, Differences, Key Insights).
   - Supports comparisons between local papers, arXiv papers, or mixed sources.

5. **PDF Export**:
   - Generates comparison reports with professional formatting (title, date, page numbers, separators).
   - Uses `Helvetica` font to avoid font loading issues (`SimSun.ttf` errors).
   - Abstracts limited to 1000 characters to prevent overflow.
   - Abstract PDFs available for download via the sidebar.

6. **Memory Management**:
   - Stores search results and uploaded papers for 30 days.
   - Automatically re-searches if previous results are empty (e.g., for `compare_web_results`).
   - Tracks recent papers and commands for quick access.

## Usage Instructions
1. **Launch the App**:
   Run `streamlit run ui.py` and open `http://localhost:8501`.

2. **Search for Papers**:
   - Enter commands in the main interface:
     - `search arxiv for vision transformer`: Lists arXiv papers.
     - `search semantic for vit max 5 last 30 days`: Lists Semantic Scholar papers.
     - `query local for transformer`: Searches local PDFs.
   - Click "â• Import Paper" to save papers to the database.

3. **Upload Papers**:
   - Use the sidebar "Upload PDF" section to upload PDFs.
   - Preview the first page and check for duplicate warnings.

4. **Compare Papers**:
   - Use commands like:
     - `compare local paper 1 with paper 2`: Compares two local papers.
     - `compare arxiv paper 1 with local paper 6`: Compares an arXiv paper with a local one.
     - `compare arxiv paper 1 with paper 2`: Compares two arXiv papers.
   - View the comparison result and click "ğŸ“¥ Export Comparison PDF".

5. **Download Abstract PDFs**:
   - In the sidebar, select a paper from the "Download Abstract PDF" dropdown.
   - Click "ğŸ“„ Download Abstract PDF" to generate a formatted PDF.

6. **View History**:
   - Enter `/history` to list recent papers in the database.

## Troubleshooting
- **PDF Chaos Issue**:
  - **Problem**: Chinese text appears as spaces or boxes.
  - **Solution**: Current version uses `Helvetica`, which does not support Chinese. To display Chinese:
    1. Download `SimSun.ttf` and place it in the project root.
    2. Update `ui.py`:
       ```python
       from reportlab.pdfbase import pdfmetrics
       from reportlab.pdfbase.ttfonts import TTFont
       pdfmetrics.registerFont(TTFont('SimSun', 'SimSun.ttf'))
       c.setFont("SimSun", 16)  # Apply to titles
       ```
- **Empty Search Results**:
  - **Problem**: "Previous search results are empty" error.
  - **Solution**: The system auto-researches using the last keyword. Ensure network connectivity and valid keywords.
- **OpenAI API Errors**:
  - **Problem**: "GPT comparison failed" or API connection issues.
  - **Solution**: Verify `OPENAI_API_KEY` in `.env`. For persistent issues, consider local models (see Future Improvements).
- **Database Connection**:
  - **Problem**: Cannot connect to PostgreSQL.
  - **Solution**: Check database credentials in `database.py` and ensure PostgreSQL is running.
- **ChromaDB Issues**:
  - **Problem**: Semantic search fails.
  - **Solution**: Verify `./chroma_db` directory exists and has write permissions.

## Future Improvements
- **Chinese Support**: Integrate `SimSun` or `NotoSansCJKsc` fonts, or translate Chinese abstracts to English using `Helsinki-NLP/opus-mt-zh-en`.
- **Remove OpenAI Dependency**: Replace `gpt-3.5-turbo` with local models like `LLaMA` or `BERT` for comparison generation.
- **Enhanced PDF Styling**: Add logos, colored headers, or customizable margins.
- **Advanced Search**: Support Boolean queries or filters (e.g., by year, author).
- **Performance Optimization**: Cache embeddings in ChromaDB for faster searches.




é€™æ˜¯ä¸€å€‹åŸºæ–¼ **Streamlit** æ§‹å»ºçš„è«–æ–‡æ‘˜è¦åˆ†æèˆ‡æŸ¥è©¢å·¥å…·ï¼Œæ•´åˆæœ¬åœ° PDF è™•ç†èˆ‡ arXiv æŸ¥è©¢åŠŸèƒ½ï¼Œä¸¦é€é GPT æ¨¡å‹å¯¦ç¾æ‘˜è¦çš„ç†è§£èˆ‡æ¯”è¼ƒã€‚

## åŠŸèƒ½ç‰¹è‰²
- âœ… **ä¸Šå‚³ PDF ä¸¦æ“·å–æ‘˜è¦**ï¼šæ”¯æ´å¾æœ¬åœ° PDF æª”æ¡ˆæå–æ¨™é¡Œèˆ‡æ‘˜è¦ã€‚
- ğŸ” **æœ¬åœ°èªæ„æŸ¥è©¢èˆ‡æ¯”è¼ƒ**ï¼šå°ä¸Šå‚³çš„è«–æ–‡æ‘˜è¦é€²è¡Œèªæ„åˆ†æèˆ‡æ¯”è¼ƒã€‚
- ğŸŒ **arXiv è«–æ–‡æŸ¥è©¢èˆ‡æ‘˜è¦æ“·å–**ï¼šå¾ arXiv åŠ Semantic Scholar ç²å–è«–æ–‡æ‘˜è¦ã€‚
- ğŸ“¤ **æ‘˜è¦ä¸‹è¼‰ç‚º PDF**ï¼šå°‡åˆ†æçµæœæˆ–æ‘˜è¦åŒ¯å‡ºç‚º PDF æ ¼å¼ã€‚
- ğŸ§  **è‡ªç„¶èªè¨€æŒ‡ä»¤æ§åˆ¶ (Agent æ¨¡å¼)**ï¼šæ”¯æ´ä»¥è‡ªç„¶èªè¨€é€²è¡Œæ“ä½œèˆ‡æŸ¥è©¢ã€‚
```
###å°ˆæ¡ˆçµæ§‹
```
llm_paper_assistant/
â”œâ”€â”€ papers/                     # ç”¨æ–¼å­˜æ”¾ä¸Šå‚³çš„ PDF æª”æ¡ˆ
â”œâ”€â”€ src/                        # åŸå§‹ç¢¼ç›®éŒ„
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py              # OpenAI å®¢æˆ¶ç«¯é…ç½®
â”‚   â”œâ”€â”€ database.py            # PostgreSQL è³‡æ–™åº«ç®¡ç†
â”‚   â”œâ”€â”€ nlp.py                 # è‡ªç„¶èªè¨€è™•ç†èˆ‡æ„åœ–è§£æ
â”‚   â”œâ”€â”€ pdf_processor.py       # PDF æ¨™é¡Œèˆ‡æ‘˜è¦æå–
â”‚   â”œâ”€â”€ compare.py             # èªæ„æ‘˜è¦æ¯”è¼ƒåŠŸèƒ½
â”‚   â”œâ”€â”€ ui.py                  # Streamlit UI å…ƒä»¶
â”‚   â”œâ”€â”€ vector_store.py        # æœ¬åœ° PDF èªæ„æœå°‹
â”‚   â”œâ”€â”€ web_search.py          # arXiv èˆ‡ Semantic Scholar æœå°‹
â”œâ”€â”€ .env                       # ç’°å¢ƒè®Šæ•¸ï¼ˆAPI é‡‘é‘°ã€è³‡æ–™åº«æ†‘è­‰ï¼‰
â”œâ”€â”€ streamlit_app.py           # Streamlit ä¸»æ‡‰ç”¨ç¨‹å¼
â”œâ”€â”€ README.md                  # å°ˆæ¡ˆæ–‡ä»¶
â”œâ”€â”€ readme.markdown            # æœ¬æ–‡ä»¶
â”œâ”€â”€ requirements.txt           # ä¾è³´å¥—ä»¶æ¸…å–®
```

###å®‰è£æ–¹å¼

### 1. å»ºç«‹è™›æ“¬ç’°å¢ƒï¼ˆå¯é¸ï¼‰
```bash
python -m venv venv
# Linux/Mac
source venv/bin/activate
# Windows
venv\Scripts\activate
```

### 2. å®‰è£ä¾è³´å¥—ä»¶
```bash
pip install -r requirements.txt
```

### 3. è¨­å®šç’°å¢ƒè®Šæ•¸
åœ¨å°ˆæ¡ˆæ ¹ç›®éŒ„ä¸‹å»ºç«‹ `.env` æª”æ¡ˆï¼Œä¸¦å¡«å…¥ä»¥ä¸‹å…§å®¹ï¼š
```
OPENAI_API_KEY=your_openai_key
DB_HOST=localhost
DB_PORT=5432
DB_NAME=your_db_name
DB_USER=your_username
DB_PASSWORD=your_password
```

### 4. å•Ÿå‹•æ‡‰ç”¨
```bash
streamlit run streamlit_app.py
```

## ä¾è³´ç‰ˆæœ¬èªªæ˜
ä»¥ä¸‹ç‚ºå°ˆæ¡ˆä½¿ç”¨çš„æ ¸å¿ƒä¾è³´å¥—ä»¶åŠå…¶ç‰ˆæœ¬ï¼Œç¢ºä¿ç©©å®šæ€§èˆ‡ç›¸å®¹æ€§ï¼ˆæˆªè‡³ 2025 å¹´ 5 æœˆï¼‰ï¼š
- `streamlit==1.38.0`: æœ€æ–°ç‰ˆæœ¬ï¼Œæ”¯æ´ Python 3.8+ï¼Œç”¨æ–¼æ§‹å»º UIã€‚
- `psycopg2-binary==2.9.9`: PostgreSQL é€£ç·šå¥—ä»¶ï¼Œæ¡ç”¨äºŒé€²åˆ¶å®‰è£ä»¥ç°¡åŒ–æµç¨‹ã€‚
- `pymupdf==1.24.9`: ç”¨æ–¼ PDF è™•ç†ï¼Œæ”¯æ´ `fitz` æ¨¡çµ„ã€‚
- `chromadb==0.5.5`: æ”¯æ´å‘é‡å„²å­˜ï¼Œèˆ‡ `llama-index-vector-stores-chroma` ç›¸å®¹ã€‚
- `python-dotenv==1.0.1`: ç’°å¢ƒè®Šæ•¸ç®¡ç†ã€‚
- `reportlab==4.2.2`: ç”¨æ–¼ç”Ÿæˆ PDFï¼Œæ”¯æ´ `canvas` åŠŸèƒ½ã€‚
- `openai==1.44.1`: æ”¯æ´ `text-embedding-3-small` å’Œ `gpt-3.5-turbo`ã€‚
- `llama-index==0.11.7`: æ ¸å¿ƒåº«ï¼Œç¢ºä¿èˆ‡å­æ¨¡çµ„ç›¸å®¹ã€‚
- `llama-index-embeddings-openai==0.2.4`: èˆ‡ `llama-index` åŒ¹é…ï¼Œç”¨æ–¼ OpenAI åµŒå…¥ã€‚
- `llama-index-vector-stores-chroma==0.2.0`: èˆ‡ `llama-index` å’Œ `chromadb` åŒ¹é…ã€‚
- `semanticscholar==0.8.3`: Semantic Scholar API å®¢æˆ¶ç«¯ï¼Œæ”¯æ´æœå°‹åŠŸèƒ½ã€‚
- `requests==2.32.3`: HTTP è«‹æ±‚è™•ç†ï¼Œå»£æ³›ç›¸å®¹ã€‚
- `numpy==1.24.4`: æ”¯æ´åµŒå…¥è¨ˆç®—ï¼Œèˆ‡ Python 3.8 ç›¸å®¹ã€‚
- `tenacity==8.5.0`: æä¾›é‡è©¦é‚è¼¯ï¼Œæ‡‰ç”¨æ–¼å¤šå€‹æ¨¡çµ„ã€‚

å®Œæ•´ä¾è³´æ¸…å–®è«‹åƒè€ƒ `requirements.txt`ã€‚

## ä½¿ç”¨å»ºè­°
- å°‡ PDF æª”æ¡ˆæ”¾ç½®æ–¼ `papers/` è³‡æ–™å¤¾ï¼Œæˆ–é€éç¶²é ä»‹é¢ä¸Šå‚³ï¼Œç³»çµ±å°‡è‡ªå‹•æå–æ‘˜è¦ä¸¦å»ºç«‹èªæ„ç´¢å¼•ã€‚
- ä½¿ç”¨è‡ªç„¶èªè¨€æŒ‡ä»¤é€²è¡ŒæŸ¥è©¢æˆ–æ¯”è¼ƒï¼Œä¾‹å¦‚ã€Œæ¯”è¼ƒé€™å…©ç¯‡è«–æ–‡çš„æ‘˜è¦ã€æˆ–ã€Œæœå°‹èˆ‡æ©Ÿå™¨å­¸ç¿’ç›¸é—œçš„ arXiv è«–æ–‡ã€ã€‚

## æª”æ¡ˆèªªæ˜
- `streamlit_app.py`: ä¸»æ‡‰ç”¨é‚è¼¯ï¼Œè² è²¬æ•´åˆæ‰€æœ‰åŠŸèƒ½ä¸¦å•Ÿå‹• Streamlit æœå‹™ã€‚
- `compare.py`: è‡ªè¨‚æ‘˜è¦æ¯”è¼ƒå‡½å¼ï¼Œæä¾›èªæ„åˆ†æèˆ‡å·®ç•°æ¯”è¼ƒã€‚
